{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi=False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from labels import mapping\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import tez\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and split it into train, valid and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_emotions = load_dataset(\"go_emotions\")\n",
    "\n",
    "data = go_emotions.data\n",
    "\n",
    "train = go_emotions.data[\"train\"].to_pandas()\n",
    "valid = go_emotions.data[\"validation\"].to_pandas()\n",
    "test = go_emotions.data[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dataset to a one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(mapping)\n",
    "\n",
    "def one_hot_labels(df):\n",
    "    dict_labels = []\n",
    "    for i in tqdm(range(len(df)), leave=False):\n",
    "        d = dict(zip(range(n_labels), [0]*n_labels))\n",
    "        labels = df.loc[i][\"labels\"]\n",
    "        for label in labels:\n",
    "            d[label] = 1\n",
    "        dict_labels.append(d)\n",
    "    df_labels = pd.DataFrame(dict_labels)\n",
    "    return df_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh_labels = one_hot_labels(train)\n",
    "valid_oh_labels = one_hot_labels(valid)\n",
    "test_oh_labels = one_hot_labels(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, train_oh_labels], axis=1)\n",
    "valid = pd.concat([valid, valid_oh_labels], axis=1)\n",
    "test = pd.concat([test, test_oh_labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, valid.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 13))\n",
    "\n",
    "ax1 = plt.subplot(3, 1, 1)\n",
    "train[range(n_labels)].mean(axis=0).plot(kind=\"bar\", ax=ax1, title=\"distribution of labels in train\")\n",
    "\n",
    "ax2 = plt.subplot(3, 1, 2)\n",
    "valid[range(n_labels)].mean(axis=0).plot(kind=\"bar\", ax=ax2, title=\"distribution of labels in validation\")\n",
    "\n",
    "ax3 = plt.subplot(3, 1, 3)\n",
    "test[range(n_labels)].mean(axis=0).plot(kind=\"bar\", ax=ax3, title=\"distribution of labels in test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(label, n=5):\n",
    "    samples = train[train[label] == 1].sample(5)\n",
    "    sentiment = mapping[label]\n",
    "    \n",
    "    print(f\"examples from {sentiment}\")\n",
    "    print()\n",
    "    for text in samples[\"text\"]:\n",
    "        print(text)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_data(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoEmotionDataset():\n",
    "    def __init__(self, texts, targets):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = transformers.SqueezeBertTokenizer.from_pretrained(\n",
    "            \"squeezebert/squeezebert-uncased\", do_lower_case=True\n",
    "        )\n",
    "        self.max_len = 35\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        target = self.targets[index]\n",
    "        text = self.texts[index]\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(text,\n",
    "                                            None,\n",
    "                                            add_special_tokens=True,\n",
    "                                            max_length=self.max_len,\n",
    "                                            padding=\"max_length\",\n",
    "                                            truncation=True)\n",
    "        \n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"targets\": torch.tensor(self.targets[index], dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a tez Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(tez.Model):\n",
    "    def __init__(self, num_train_steps, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = transformers.SqueezeBertModel.from_pretrained(\"squeezebert/squeezebert-uncased\")\n",
    "        self.bert_drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(768, num_classes)\n",
    "        self.num_train_steps = num_train_steps\n",
    "        self.step_scheduler_after = \"batch\"\n",
    "    \n",
    "    def fetch_optimizer(self):\n",
    "        param_optimizer = list(self.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\"]\n",
    "        optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.001,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        opt = AdamW(optimizer_parameters, lr=3e-5)\n",
    "        return opt\n",
    "\n",
    "    \n",
    "    def fetch_scheduler(self):\n",
    "        sch = get_linear_schedule_with_warmup(\n",
    "            self.optimizer, num_warmup_steps=0, num_training_steps=self.num_train_steps\n",
    "        )\n",
    "        return sch\n",
    "    \n",
    "    def loss(self, outputs, targets):\n",
    "        if targets is None:\n",
    "            return None\n",
    "        return nn.BCEWithLogitsLoss()(outputs, targets.float())\n",
    "    \n",
    "    \n",
    "    def monitor_metrics(self, outputs, targets):\n",
    "        if targets is None:\n",
    "            return {}\n",
    "        \n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        targets = targets.cpu().detach().numpy()\n",
    "        \n",
    "        fpr_micro, tpr_micro, _ = metrics.roc_curve(targets.ravel(), outputs.ravel())\n",
    "        auc_micro = metrics.auc(fpr_micro, tpr_micro)\n",
    "        return {\"auc\": auc_micro}\n",
    " \n",
    "    \n",
    "    def forward(self, ids, mask, targets=None):\n",
    "        o_2 = self.bert(ids, attention_mask=mask)[\"pooler_output\"]\n",
    "        b_o = self.bert_drop(o_2)\n",
    "        output = self.out(b_o)\n",
    "        loss = self.loss(output, targets)\n",
    "        acc = self.monitor_metrics(output, targets)\n",
    "        return output, loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GoEmotionDataset(train.text.tolist(), train[range(n_labels)].values.tolist())\n",
    "valid_dataset = GoEmotionDataset(valid.text.tolist(), valid[range(n_labels)].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_steps = int(len(train) / 32 * 10)\n",
    "model = EmotionClassifier(n_train_steps, n_labels)\n",
    "\n",
    "tb_logger = tez.callbacks.TensorBoardLogger(log_dir=\"logs/\")\n",
    "es = tez.callbacks.EarlyStopping(monitor=\"valid_loss\", model_path=\"export/model.bin\")\n",
    "\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          valid_dataset, \n",
    "          train_bs=64,\n",
    "          device=\"cuda\", \n",
    "          epochs=8, \n",
    "          callbacks=[tb_logger, es], \n",
    "          fp16=True, \n",
    "          n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = GoEmotionDataset(test.text.tolist(), test[range(n_labels)].values.tolist())\n",
    "dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        output, loss, acc = model.forward(batch[\"ids\"].to(\"cuda\"), \n",
    "                                          batch[\"mask\"].to(\"cuda\"), \n",
    "                                          #batch[\"token_type_ids\"].to(\"cuda\"),\n",
    "                                          batch[\"targets\"].to(\"cuda\")\n",
    "                                         )\n",
    "        outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.cat(outputs)\n",
    "outputs = torch.sigmoid(outputs)\n",
    "outputs = outputs.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_metrics = []\n",
    "\n",
    "for i in range(n_labels):\n",
    "    roc = metrics.roc_auc_score(test[i].values, outputs[:, i])\n",
    "    roc_metrics.append(roc)\n",
    "\n",
    "s = pd.Series(roc_metrics, index=range(n_labels))\n",
    "\n",
    "s.plot(kind=\"bar\", figsize=(20, 5), title=\"roc auc score per class on test data\", grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.SqueezeBertTokenizer.from_pretrained(\n",
    "            \"squeezebert/squeezebert-uncased\", do_lower_case=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentence(text, topn=5):\n",
    "    max_len = 35\n",
    "    with torch.no_grad():\n",
    "\n",
    "        inputs = tokenizer.encode_plus(text,\n",
    "                                       None,\n",
    "                                       add_special_tokens=True,\n",
    "                                       max_length=max_len,\n",
    "                                       padding=\"max_length\",\n",
    "                                       truncation=True)\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        ids = torch.LongTensor(ids).cuda().unsqueeze(0)\n",
    "\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        attention_mask = torch.LongTensor(attention_mask).cuda().unsqueeze(0)\n",
    "\n",
    "        output = model.forward(ids, attention_mask)[0]\n",
    "        output = torch.sigmoid(output)\n",
    "\n",
    "        probas, indices = torch.sort(output)\n",
    "\n",
    "    probas = probas.cpu().numpy()[0][::-1]\n",
    "    indices = indices.cpu().numpy()[0][::-1]\n",
    "\n",
    "    for i, p in zip(indices[:topn], probas[:topn]):\n",
    "        print(mapping[i], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sentence(\"i miss my friends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sentence(\"funny how this craps out!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sentence(\"go to hell! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sentence(\"you might have a point, but i strongly disagree with you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sentence(\"i'm feeling very confident about this situation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sentence(\"try to be safe my friend\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt1.5]",
   "language": "python",
   "name": "conda-env-pt1.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
